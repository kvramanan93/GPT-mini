{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h5hjCcLDr2WC",
    "outputId": "ccc60f0c-fd78-4dbe-8598-0512d1036aad",
    "ExecuteTime": {
     "end_time": "2024-09-03T21:12:43.814519Z",
     "start_time": "2024-09-03T21:12:43.704546Z"
    }
   },
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Save the response content to a file\n",
    "with open('input.txt', 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# Now read it in to inspect it\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"length of dataset in characters: \", len(text))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6xWI_VyAsN8F",
    "outputId": "ed819dd0-72e5-40a6-d2ed-928ff73bfda6",
    "ExecuteTime": {
     "end_time": "2024-09-03T21:12:45.711908Z",
     "start_time": "2024-09-03T21:12:45.708145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  1115394\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "# let's look at the first 1000 characters\n",
    "print(text[:1000])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2c5V0FvqseE0",
    "outputId": "25ca7adc-b8c0-42d1-b08c-e0863c5c314e",
    "ExecuteTime": {
     "end_time": "2024-09-03T21:12:47.621792Z",
     "start_time": "2024-09-03T21:12:47.617282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)\n",
    "#Possible characters for this model to see."
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e-Rbyr8sfM8",
    "outputId": "f34e94a9-5b44-4cf3-885b-986731929109",
    "ExecuteTime": {
     "end_time": "2024-09-03T21:12:49.611672Z",
     "start_time": "2024-09-03T21:12:49.600743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string || Reverse Mapping\n",
    "\n",
    "print(encode(\"hii there\"))\n",
    "print(decode(encode(\"hii there\"))) "
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yw1LKNCgwjj1",
    "outputId": "86fcc21c-2cf7-40d9-cd7b-b5a253da4459",
    "ExecuteTime": {
     "end_time": "2024-09-03T21:14:59.142924Z",
     "start_time": "2024-09-03T21:14:59.138034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
      "hii there\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Note: Everyone use their own version of tokenizers\n",
    "  * Google uses SentencePiece which is a subword tokenizer.Doesn't encode entire word and doesn't encode single characters.\n",
    "    * TikToken for OpenAI - Has about 50k tokens \n",
    "    Can trade off the codebook size and seq lence\n",
    "        * Can have long seq with small vocab or can have short seq of integers with huge vocabularies."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# let's now encode the entire text dataset and store it into a torch.Tensor\n",
    "import torch # we use PyTorch: https://pytorch.org\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000]) # the 1000 characters we looked at earier will to the GPT look like this"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJb0OXPwzvqg",
    "outputId": "db7297cc-36a9-4fae-e941-e7bb9e0e91d1",
    "ExecuteTime": {
     "end_time": "2024-09-03T21:25:57.062125Z",
     "start_time": "2024-09-03T21:25:56.956012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "# Let's now split up the data into train and validation sets\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ],
   "metadata": {
    "id": "f_WIXqxz0lU5",
    "ExecuteTime": {
     "end_time": "2024-09-03T21:26:05.529228Z",
     "start_time": "2024-09-03T21:26:05.518724Z"
    }
   },
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "block_size = 8   # Context size\n",
    "train_data[:block_size+1] # This carries multiple individual examples\n",
    "#Cant train the entire dataset on transformer because it will be conputationally expensive hence we divide it into chunks"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TD5Bj8Y6IAD4",
    "outputId": "bf23c586-1d33-4af1-b63d-ce6f90b0a528",
    "ExecuteTime": {
     "end_time": "2024-09-03T21:27:32.675184Z",
     "start_time": "2024-09-03T21:27:32.669587Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1] # Targets for each position for input\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1] # All characters upto t\n",
    "    target = y[t] # Target character\n",
    "    print(f\"when input is {context} the target: {target}\")\n",
    "    #This is made to make sure that the transformer understands the context within the blocks.So transformer can learn to predict the \n",
    "    #Char upto blocksize of 1"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9HXDe8vGJCEn",
    "outputId": "588663aa-1de5-4ef7-aba0-4a96fe828353",
    "ExecuteTime": {
     "end_time": "2024-09-03T21:30:39.341352Z",
     "start_time": "2024-09-03T21:30:39.336110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]) the target: 47\n",
      "when input is tensor([18, 47]) the target: 56\n",
      "when input is tensor([18, 47, 56]) the target: 57\n",
      "when input is tensor([18, 47, 56, 57]) the target: 58\n",
      "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # Number of independent sequences that will we processed in parallel\n",
    "block_size = 8 # Maximum context length for predictions\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    #print(\"Data Length:\",len(data))\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    #print(\"ix Length:\",len(ix))\n",
    "    #print(\"x\",ix)\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(block_size): # time dimension / Represents the sequence or timesteps in our data.\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q3k1Czf7LuA9",
    "outputId": "4ea8e8a0-443c-49bb-b3bf-ba36e1712999",
    "ExecuteTime": {
     "end_time": "2024-09-03T22:23:59.746509Z",
     "start_time": "2024-09-03T22:23:59.739014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "----\n",
      "when input is [24] the target: 43\n",
      "when input is [24, 43] the target: 58\n",
      "when input is [24, 43, 58] the target: 5\n",
      "when input is [24, 43, 58, 5] the target: 57\n",
      "when input is [24, 43, 58, 5, 57] the target: 1\n",
      "when input is [24, 43, 58, 5, 57, 1] the target: 46\n",
      "when input is [24, 43, 58, 5, 57, 1, 46] the target: 43\n",
      "when input is [24, 43, 58, 5, 57, 1, 46, 43] the target: 39\n",
      "when input is [44] the target: 53\n",
      "when input is [44, 53] the target: 56\n",
      "when input is [44, 53, 56] the target: 1\n",
      "when input is [44, 53, 56, 1] the target: 58\n",
      "when input is [44, 53, 56, 1, 58] the target: 46\n",
      "when input is [44, 53, 56, 1, 58, 46] the target: 39\n",
      "when input is [44, 53, 56, 1, 58, 46, 39] the target: 58\n",
      "when input is [44, 53, 56, 1, 58, 46, 39, 58] the target: 1\n",
      "when input is [52] the target: 58\n",
      "when input is [52, 58] the target: 1\n",
      "when input is [52, 58, 1] the target: 58\n",
      "when input is [52, 58, 1, 58] the target: 46\n",
      "when input is [52, 58, 1, 58, 46] the target: 39\n",
      "when input is [52, 58, 1, 58, 46, 39] the target: 58\n",
      "when input is [52, 58, 1, 58, 46, 39, 58] the target: 1\n",
      "when input is [52, 58, 1, 58, 46, 39, 58, 1] the target: 46\n",
      "when input is [25] the target: 17\n",
      "when input is [25, 17] the target: 27\n",
      "when input is [25, 17, 27] the target: 10\n",
      "when input is [25, 17, 27, 10] the target: 0\n",
      "when input is [25, 17, 27, 10, 0] the target: 21\n",
      "when input is [25, 17, 27, 10, 0, 21] the target: 1\n",
      "when input is [25, 17, 27, 10, 0, 21, 1] the target: 54\n",
      "when input is [25, 17, 27, 10, 0, 21, 1, 54] the target: 39\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "source": [
    "print(xb) # our input to the transformer"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qpyyAeIzQjlO",
    "outputId": "a650f8dc-da81-400b-bc59-0a595487fdb9",
    "ExecuteTime": {
     "end_time": "2024-09-03T21:46:55.143Z",
     "start_time": "2024-09-03T21:46:55.138910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T22:06:47.974750Z",
     "start_time": "2024-09-03T22:06:47.952201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C) Batch - 4, Time/Block size - 8, Channel/Vocab Size - 65\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T) \n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            #We're doing this becuuse in Pytorch Docs if its multidimentional input for crossentropy then it needds B, C,T input which is a mess for now, so we stretched our input\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    # Sampling to create a sequence of tokens starting from the initial context. Iteratively predicts the next token, samples from the predicted probability distribution and appends the sampled token to the sequence.(Useful for generating text or sequences based on the learned patterns of the language model.\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "# Loss in neg log likelihood = ln(1/65)*-1 initial conditions super diffused. got some entropy\n",
    "\n",
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "source": [
    "# creating a PyTorch optimizer (To take gradients and update parameters based on the grads)\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ],
   "metadata": {
    "id": "eTyJ8qAaDdiF",
    "ExecuteTime": {
     "end_time": "2024-09-03T22:17:41.218170Z",
     "start_time": "2024-09-03T22:17:41.212712Z"
    }
   },
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000): # increase number of steps for good results...\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward() # This computes the gradient of the loss with respect to each parameter of the mode\n",
    "    optimizer.step() #This updates the model parameters using the gradients computed in the previous step\n",
    "\n",
    "print(loss.item())\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hs4kI8YdEkQj",
    "outputId": "42ded55c-2983-4d91-c528-675b2edfa849",
    "ExecuteTime": {
     "end_time": "2024-09-03T22:25:29.090673Z",
     "start_time": "2024-09-03T22:25:13.875109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.390383243560791\n"
     ]
    }
   ],
   "execution_count": 126
  },
  {
   "cell_type": "code",
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))\n",
    "# This is going to look janky because the model ddint learn context."
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EcVIDWAZEtjN",
    "outputId": "0ad6f9d2-ad58-4498-a5f8-6f31407bb18b",
    "ExecuteTime": {
     "end_time": "2024-09-03T22:25:32.780385Z",
     "start_time": "2024-09-03T22:25:32.728938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rule meloulare, my tour; ass, gof.\n",
      "hid ue waimy wad vild me d trardeay pifoff? Se bris stile gotey ull thedecthatrsese ththa hesu oravewsatheno st he fe, awn hicaton beesun bewod,\n",
      "D a so 'llental d,\n",
      "A:\n",
      "ist\n",
      "Bys areinst:\n",
      "\n",
      "ORARon 's If Theakind ssauald'tarecillisce end?\n",
      "The surthen an yoltoler, o--thincanow, ple asor fond lsesteond y t iunor ved thitt paieneeinoure loraresot by cors\n",
      "ARELI'theno;\n",
      "Jved mse? Ple ishare itick hte! d din it'd\n",
      "ANRI:\n",
      "\n",
      "Thee pllatoof!\n",
      "Sos hanory knuthaghe me\n",
      "ILOf in ge ngmy\n"
     ]
    }
   ],
   "execution_count": 127
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The mathematical trick in self-attention"
   ],
   "metadata": {
    "id": "XinV8nmAnmKN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tukiH-NbRBhA",
    "outputId": "d981f6d4-ac08-4ec2-8284-82f5fa1e0815",
    "ExecuteTime": {
     "end_time": "2024-09-03T22:25:47.503174Z",
     "start_time": "2024-09-03T22:25:47.479944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "execution_count": 128
  },
  {
   "cell_type": "code",
   "source": [
    "# example:\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hs_E24uRE8kr",
    "outputId": "8bf3ff5f-565e-48b8-de8e-7272706c8e12",
    "ExecuteTime": {
     "end_time": "2024-09-03T22:51:27.597362Z",
     "start_time": "2024-09-03T22:51:27.586504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 129
  },
  {
   "cell_type": "code",
   "source": [
    "# We want x[b,t] = mean_{i<=t} x[b,i]\n",
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] # (t,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0)\n"
   ],
   "metadata": {
    "id": "86NuXX0fn7ps",
    "ExecuteTime": {
     "end_time": "2024-09-03T23:25:04.013237Z",
     "start_time": "2024-09-03T23:25:04.002573Z"
    }
   },
   "outputs": [],
   "execution_count": 135
  },
  {
   "cell_type": "code",
   "source": [
    "# version 2: using matrix multiply for a weighted aggregation\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
    "torch.allclose(xbow, xbow2)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yhdOAd6-wXkZ",
    "outputId": "eaf6ab61-dff1-4bb7-e623-47f692bad5f9",
    "ExecuteTime": {
     "end_time": "2024-09-03T23:21:43.539949Z",
     "start_time": "2024-09-03T23:21:43.512197Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 131
  },
  {
   "cell_type": "code",
   "source": [
    "# version 3: use Softmax\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T,T)) #initializing affinities to all the tokens as zero \n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "#Softmax is applied to convert the masked weights to probability distribution along the last dimension. Softmax ensures the valuies in each row sum to 1 turning the values into valid probabilities\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wOURrfG-ysoL",
    "outputId": "080b500d-8110-4602-fcef-7d6f2ebfc6bc",
    "ExecuteTime": {
     "end_time": "2024-09-03T23:50:39.481980Z",
     "start_time": "2024-09-03T23:50:39.474768Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 137
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Query and Key vector are emmmited from an Attention block \n",
    "* Query vectorâ€”looks at what am I looking for?\n",
    "* Key vector- What do i contain?\n",
    "* Query dot products with keys of other vectors and that dot pdt is wei."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# version 4: self-attention!\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 # batch, time, channels - Information in each token is 32 dimensional \n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# Single Head perform self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "#print(key)\n",
    "#print(key.weight)\n",
    "k = key(x)   # (B, T, 16)\n",
    "print(\"Key: \",k[0])\n",
    "q = query(x) # (B, T, 16)\n",
    "print(\"Query: \",q[0])\n",
    "\n",
    "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "# For every row of B we got T2 sq matrix of affinities.\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "#wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "#out = wei @ x\n",
    "# We dont aggregate token instead of raw X\n",
    "# Wei contains attention weights.\n",
    "out.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EDarxEWIRMKq",
    "outputId": "07b587dd-a91c-4bb0-d7f1-e247cd5dacb5",
    "ExecuteTime": {
     "end_time": "2024-09-04T00:27:25.647095Z",
     "start_time": "2024-09-04T00:27:25.633678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-6.8099e-02, -9.8643e-02, -1.7349e-01, -1.6352e-01, -1.2964e-01,\n",
      "         -1.1857e-01, -8.7935e-02,  1.6583e-01,  1.1149e-01,  1.0582e-01,\n",
      "          4.0458e-02, -6.8736e-02,  8.9122e-02, -1.0246e-01,  4.3951e-02,\n",
      "          4.2129e-02,  1.6920e-01,  2.2799e-02, -9.9933e-02,  2.2683e-02,\n",
      "          1.2836e-01,  4.4120e-02, -1.0471e-01,  3.8123e-02, -4.5111e-02,\n",
      "         -7.9258e-02, -1.7935e-02,  7.6775e-02,  1.4630e-01, -1.8789e-02,\n",
      "          7.3976e-02, -1.1801e-01],\n",
      "        [-1.0961e-01,  3.2653e-02,  7.5895e-02, -1.4005e-01,  7.3747e-02,\n",
      "         -3.6804e-02, -8.7175e-02,  1.2370e-01,  5.4620e-02, -1.0754e-01,\n",
      "          7.8234e-02, -1.1427e-01,  1.6300e-01,  1.3302e-01,  1.4679e-01,\n",
      "          1.0177e-01, -6.3109e-02,  3.5280e-02, -1.0740e-01,  1.1088e-01,\n",
      "         -6.8315e-02, -4.0772e-02, -1.4297e-01,  1.0250e-01,  1.6506e-01,\n",
      "          1.5242e-01, -7.8625e-02,  1.6294e-01,  1.6277e-01,  1.0856e-01,\n",
      "         -3.0436e-02,  2.4977e-02],\n",
      "        [ 1.5249e-01,  1.0275e-01,  4.3278e-02, -9.5505e-02,  1.7025e-01,\n",
      "          1.1497e-01, -5.7625e-02,  1.3853e-01,  4.4039e-02,  3.8374e-02,\n",
      "          1.6110e-02, -4.2688e-02,  1.3080e-01,  9.7571e-02, -1.0704e-01,\n",
      "         -1.3652e-01, -4.1222e-02, -1.1122e-01,  1.7165e-01,  5.2773e-02,\n",
      "         -7.9819e-02,  3.4995e-02, -2.8419e-02,  1.0930e-01, -1.1332e-01,\n",
      "          3.9481e-02, -2.7924e-02,  1.6452e-01, -1.1433e-01, -4.2354e-02,\n",
      "          2.8936e-02,  2.4281e-02],\n",
      "        [-9.7882e-02, -6.0722e-02, -6.6289e-02,  8.3226e-02,  3.7641e-02,\n",
      "          1.3100e-01,  8.7523e-02,  1.6533e-01, -1.4601e-01,  1.0506e-01,\n",
      "          2.9965e-02, -6.3981e-03,  1.4121e-01, -1.7219e-01, -7.4150e-02,\n",
      "         -1.2638e-01,  6.2434e-02, -1.1486e-01, -7.5343e-02,  3.0203e-02,\n",
      "         -7.9778e-02,  1.3633e-01,  1.5300e-01, -6.3099e-02, -5.3324e-02,\n",
      "         -1.2593e-01, -1.6868e-02,  7.2576e-02, -3.1120e-02,  1.4086e-01,\n",
      "          1.0126e-01,  1.5966e-01],\n",
      "        [-7.6292e-02,  1.3646e-01,  1.1821e-01, -9.8031e-02, -1.3021e-01,\n",
      "         -1.4731e-01,  3.4453e-03,  1.0337e-01, -7.0868e-02, -7.7632e-02,\n",
      "         -5.9857e-02, -1.0905e-01,  8.0371e-02,  1.7287e-01, -1.1660e-01,\n",
      "          5.2768e-02,  2.7183e-02,  9.1675e-02,  5.2509e-02,  1.2185e-01,\n",
      "         -5.5289e-02,  1.6177e-01, -5.7607e-02, -1.6536e-01,  9.8512e-02,\n",
      "         -4.3722e-02, -8.0836e-02,  6.9600e-02,  7.5654e-02, -1.6000e-01,\n",
      "          1.4653e-01,  1.2013e-01],\n",
      "        [ 1.1849e-02, -6.1931e-02, -1.6487e-01,  1.2937e-01, -1.7419e-01,\n",
      "         -1.7408e-01,  1.2553e-01, -4.1306e-02, -1.2633e-01,  1.3249e-01,\n",
      "          2.7612e-02, -1.2028e-01,  6.5609e-02,  1.6821e-01, -2.5480e-03,\n",
      "          1.3817e-01, -1.0835e-01, -1.6294e-01,  8.0848e-02,  3.8297e-02,\n",
      "          5.1866e-02,  3.6717e-02, -1.5403e-01,  1.2956e-02, -6.8713e-02,\n",
      "         -2.9291e-02, -8.3056e-02,  1.1445e-01, -1.2888e-01,  1.2095e-01,\n",
      "         -1.6900e-01,  6.3313e-02],\n",
      "        [-2.0638e-02,  3.7359e-02, -8.3009e-02, -1.5501e-01,  9.8815e-02,\n",
      "          1.8601e-02, -1.4679e-01,  6.6183e-02, -1.6571e-01, -7.2415e-02,\n",
      "          5.4227e-02, -8.9693e-02, -1.4622e-01, -2.9553e-02,  8.3313e-02,\n",
      "          1.7542e-01, -1.2048e-01,  9.5010e-02, -8.4487e-02, -3.5018e-02,\n",
      "          2.9058e-02,  1.0718e-01, -4.0137e-02, -9.7460e-02, -2.4583e-02,\n",
      "         -3.6588e-02,  1.1280e-01,  8.6134e-03,  4.6095e-02, -1.2786e-02,\n",
      "          4.4905e-02,  1.5807e-01],\n",
      "        [ 1.0356e-01,  1.5338e-01,  8.5929e-02, -1.0786e-01,  1.3260e-01,\n",
      "          8.5842e-02,  7.1748e-02, -5.1793e-02,  7.9536e-02, -7.8420e-02,\n",
      "          3.8664e-02,  4.8593e-02, -8.4905e-03, -1.1840e-01,  1.3581e-01,\n",
      "          4.7156e-02, -1.6053e-01, -2.1001e-02,  1.5968e-01, -1.1998e-01,\n",
      "         -1.2472e-01,  9.7064e-02, -3.5927e-02,  1.3178e-01, -1.1117e-01,\n",
      "         -1.5646e-01,  1.5013e-01,  1.5899e-01,  7.9425e-02,  9.1589e-03,\n",
      "         -3.8599e-03, -1.6853e-01],\n",
      "        [-1.2575e-01,  1.0590e-02,  1.1244e-01,  1.2312e-01,  6.3408e-02,\n",
      "          7.0045e-02, -2.5557e-02, -3.6808e-02, -3.2455e-02,  6.8339e-03,\n",
      "          2.4582e-02, -1.5945e-01,  6.3876e-02,  1.3194e-01,  3.1784e-02,\n",
      "         -6.1861e-02, -6.1105e-02, -4.6992e-02, -8.4206e-02,  5.4601e-02,\n",
      "          9.9015e-02,  1.0901e-01, -3.2522e-03, -8.6210e-03,  7.9927e-02,\n",
      "          5.1997e-02,  1.1535e-01, -8.3316e-02,  4.3422e-03, -5.3101e-03,\n",
      "          1.5484e-02, -3.6204e-02],\n",
      "        [-1.3669e-01,  1.0733e-01, -1.0687e-01, -6.7400e-02, -7.2555e-02,\n",
      "         -1.3350e-01, -1.4455e-01,  1.0717e-01,  5.2613e-02,  1.7002e-01,\n",
      "          8.8344e-02,  1.0909e-01,  7.9633e-02,  1.4011e-01, -7.9092e-02,\n",
      "         -1.1710e-02, -1.4749e-01, -1.4848e-01, -1.2368e-01, -1.0331e-01,\n",
      "          9.7965e-02, -8.5487e-02,  2.5807e-02, -6.9761e-02, -3.9997e-02,\n",
      "         -1.8978e-02, -1.4992e-01,  6.6338e-02,  6.7267e-02,  1.2758e-01,\n",
      "         -1.3775e-01, -1.3470e-01],\n",
      "        [-4.5076e-02, -3.7608e-02, -6.6963e-02,  1.3201e-01, -8.0726e-02,\n",
      "          1.8431e-02, -3.7742e-02,  1.1775e-01, -3.9311e-02, -8.6289e-02,\n",
      "         -1.8587e-02, -6.3370e-03, -9.9040e-03,  1.0718e-01, -1.5877e-02,\n",
      "          3.6025e-02,  9.0590e-02,  1.5886e-01,  1.5089e-01,  1.9816e-02,\n",
      "         -3.8670e-02,  1.5069e-01,  5.9421e-03,  1.3847e-01, -3.3106e-02,\n",
      "         -7.0869e-02, -1.3390e-01, -8.2043e-02, -1.2114e-01, -1.6049e-02,\n",
      "         -5.0185e-02,  1.5595e-01],\n",
      "        [ 1.4940e-01, -4.6724e-02, -8.0221e-02,  1.6561e-01,  1.4387e-01,\n",
      "         -9.4793e-02,  1.0663e-02,  8.4980e-02,  7.9517e-04,  4.2015e-02,\n",
      "         -7.7001e-02, -1.4818e-01, -2.6448e-02,  1.2588e-01, -1.0159e-01,\n",
      "         -1.3217e-01, -7.7225e-02, -1.2626e-01,  7.2574e-02, -2.9537e-02,\n",
      "          1.0763e-01, -1.7656e-01,  9.8042e-02,  1.6602e-01, -1.0055e-01,\n",
      "          9.2840e-02,  1.1662e-01,  1.1124e-01, -3.4315e-03, -1.1784e-01,\n",
      "         -1.0108e-01, -1.4137e-01],\n",
      "        [ 9.6783e-03,  8.6963e-02,  1.7211e-01,  6.5054e-02, -2.0855e-02,\n",
      "          1.4930e-02,  1.3165e-01,  6.1358e-02, -6.0564e-03, -1.3671e-01,\n",
      "         -1.2487e-01,  5.3119e-02, -1.1370e-01,  4.4917e-02, -1.3812e-01,\n",
      "         -1.4399e-01, -1.5495e-01, -6.0918e-02,  7.4377e-02, -1.1873e-01,\n",
      "          1.3281e-01, -1.0350e-01, -1.5391e-01, -2.5220e-02,  1.0324e-01,\n",
      "         -1.1022e-01, -2.6089e-02,  5.2333e-02,  1.1281e-01, -2.4862e-02,\n",
      "         -8.2146e-02,  8.4052e-02],\n",
      "        [ 4.8880e-02,  8.2953e-02, -1.1199e-01,  1.4349e-01, -5.1182e-03,\n",
      "          6.2781e-02, -1.2521e-01,  1.1052e-01, -9.5320e-02, -1.1535e-01,\n",
      "         -1.6347e-01,  1.3836e-01, -1.2869e-01, -3.1336e-02,  4.7716e-02,\n",
      "         -6.3542e-02, -1.0404e-01,  2.7039e-02,  2.3985e-02, -2.6511e-02,\n",
      "          4.0839e-02,  9.6727e-03, -2.4466e-02,  9.9112e-03,  8.2124e-02,\n",
      "         -1.2607e-01, -9.5220e-02,  3.2283e-02,  1.0801e-02, -1.0005e-01,\n",
      "         -4.6586e-02,  1.7057e-01],\n",
      "        [-1.3919e-03,  8.8185e-02,  2.1750e-02,  6.3945e-02, -1.1831e-02,\n",
      "          2.3331e-02,  8.5274e-02, -7.0917e-02, -1.5361e-01, -4.6353e-02,\n",
      "         -3.5673e-03,  1.4416e-01, -1.2825e-01, -1.7148e-01, -1.2771e-01,\n",
      "         -4.9168e-02, -1.0071e-01, -9.8324e-03,  7.9859e-02, -9.2871e-02,\n",
      "         -9.4987e-02, -5.1714e-03,  3.2602e-02,  8.4125e-02, -1.0444e-01,\n",
      "          1.1154e-01, -9.4067e-02,  7.3866e-02,  3.9404e-02,  9.8618e-02,\n",
      "          1.0545e-01,  1.5279e-02],\n",
      "        [-1.9802e-02, -3.3240e-02, -1.5069e-01,  1.2643e-01,  1.1403e-01,\n",
      "         -3.3752e-02,  1.9119e-02,  4.2919e-03,  3.6436e-02,  1.3688e-01,\n",
      "         -4.4100e-02, -8.0821e-02, -1.3136e-01, -1.6749e-01,  8.9439e-02,\n",
      "          1.1643e-01, -9.6840e-02, -1.7501e-01,  3.1230e-02, -4.6910e-02,\n",
      "          1.0724e-02, -6.1023e-02,  4.4554e-02,  3.7684e-02, -8.1541e-02,\n",
      "          1.2171e-01, -4.0308e-05, -6.4351e-03,  2.4787e-02, -1.1204e-01,\n",
      "          1.2286e-01, -7.6555e-02]], requires_grad=True)\n",
      "Key:  tensor([[ 0.1196, -0.3013,  0.3629,  1.1771,  1.1385, -0.2554,  0.1454, -0.2944,\n",
      "         -0.7020, -1.0308,  0.7436, -0.8098, -0.6669,  0.0912, -0.0061,  0.1983],\n",
      "        [-0.5423, -0.5558, -0.0761,  1.2929,  0.8653, -1.1998,  0.3878,  0.1939,\n",
      "          0.7024, -0.8225,  0.2348, -0.8499, -0.3813, -0.2991,  0.0102, -0.5545],\n",
      "        [-0.3736, -0.4678, -0.2156, -0.8034, -0.3715, -0.5443, -0.9146, -0.0559,\n",
      "         -0.3290, -0.2102,  0.1166, -0.1798, -0.2820, -0.3320, -0.4596, -0.1325],\n",
      "        [-0.3146,  0.0845, -0.1235, -0.7058, -0.1802,  0.5492, -0.8980, -0.4938,\n",
      "          0.6791,  0.8827,  0.4911,  0.5190,  0.9011,  0.0913, -0.1933, -0.6770],\n",
      "        [ 0.0239,  0.0998, -0.1871, -0.0860, -0.4881, -1.6765,  0.2413,  0.7361,\n",
      "          0.4608, -0.8722, -0.4259, -1.1347, -1.0571, -0.9401,  0.1343, -0.0157],\n",
      "        [-0.2362, -0.7873, -0.3802,  0.5815, -0.3722,  1.2405, -0.7004, -1.4917,\n",
      "          0.7678,  0.3584,  0.6120, -0.0794,  0.5983,  0.2635,  0.6490,  0.0709],\n",
      "        [-0.7941, -0.1660, -0.2810, -0.1021, -0.7352, -0.7518, -0.1276, -0.0051,\n",
      "          0.3325, -0.3374,  0.1678,  0.3105,  0.2258,  0.1243,  0.4617,  0.2016],\n",
      "        [ 0.1651, -0.1599, -0.5717, -0.3957,  0.3930, -0.8567,  0.3390, -0.7977,\n",
      "          0.2213, -0.5161,  0.1850, -0.2105,  0.3779,  0.0482, -0.4744, -0.0504]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Query:  tensor([[-0.6567,  0.0283,  0.0094, -0.6995, -0.3604,  0.8376, -0.4446,  0.1228,\n",
      "          0.6276, -0.6222,  0.3483,  0.2411,  0.5409, -0.2605,  0.3612, -0.0436],\n",
      "        [-0.3932,  0.8220, -0.7027,  0.0954, -0.1222, -0.1518, -0.5024, -0.4636,\n",
      "          0.1176,  1.4282, -0.5812,  0.1401,  0.9604,  0.0410, -0.6214, -0.6347],\n",
      "        [ 0.2157, -0.3507,  0.0022,  0.4232, -0.2284, -0.0732, -0.3412,  0.9647,\n",
      "         -0.5178,  0.0921, -0.5043,  0.8388,  0.6149, -0.0109, -0.5569,  0.5820],\n",
      "        [ 0.9000, -0.1272,  0.5458,  0.4254, -0.4513, -0.0212,  0.1711,  0.2599,\n",
      "         -0.9978,  0.4890,  0.1737, -0.0700, -0.3113,  0.3748, -0.1848, -0.6379],\n",
      "        [ 0.0332,  0.5886, -0.4437,  0.3775, -0.6826, -0.2775,  0.4673, -1.2956,\n",
      "          0.6603,  0.1633, -1.7573, -0.6582, -0.2302, -0.0862, -0.0060,  0.7573],\n",
      "        [ 0.2098,  0.0439, -0.0702,  0.0727, -0.2012, -1.7539,  1.0369,  0.1163,\n",
      "          0.2956,  0.3231,  0.5052,  0.7011, -0.2844, -0.7844,  0.4782, -0.5170],\n",
      "        [ 0.6100, -0.3284, -0.8557,  0.8543,  0.7805, -0.4023, -0.8183, -0.0554,\n",
      "          0.1873,  0.2706, -0.7066, -0.8637,  0.6998, -0.0670,  0.2551,  0.2149],\n",
      "        [ 0.1459,  0.1349, -0.2335, -0.0417,  0.2928, -0.5080,  0.1177,  0.1861,\n",
      "          0.1455,  0.0292, -0.8470,  0.6116,  1.2445,  0.1909,  0.3694, -0.0027]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 149
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* Self-Attention is a mechanism that allows a model to weigh the importance of different tokens in a sequence relative to each other.\n",
    "* It involves computing attention scores, which determine how much focus each token should have on other tokens in the sequence.\n",
    "* Every Node has some vector of information and it gets to aggregate information via a weighted sum from all the nodes that point to it."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "wei[0]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vT1hdtzXCjgL",
    "outputId": "6d2c569b-7922-451f-9934-0fc564678d17",
    "ExecuteTime": {
     "end_time": "2024-09-04T00:14:22.009707Z",
     "start_time": "2024-09-04T00:14:22.004896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
       "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
       "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 140
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notes:\n",
    "- Attention is a **communication mechanism**. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
    "- There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens.\n",
    "- Each example across batch dimension is of course processed completely independently and never \"talk\" to each other\n",
    "- In an \"encoder\" attention block just delete the single line that does masking with `tril`, allowing all tokens to communicate. This block here is called a \"decoder\" attention block because it has triangular masking, and is usually used in autoregressive settings, like language modeling.(Allows all nodes to talk to each other in encoder block)\n",
    "- \"self-attention\" just means that the keys and values are produced from the same source as queries. In \"cross-attention\", the queries still get produced from x, but the keys and values come from some other, external source (e.g. an encoder module)\n",
    "- \"Scaled\" attention additional divides `wei` by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and Softmax will stay diffuse and not saturate too much. Illustration below"
   ],
   "metadata": {
    "id": "M5CvobiQ0pLr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "k = torch.randn(B,T,head_size)\n",
    "q = torch.randn(B,T,head_size)\n",
    "wei = q @ k.transpose(-2, -1) * head_size**-0.5"
   ],
   "metadata": {
    "id": "4SNbLq5z3oBw"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "k.var()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nl6I9n9IRTSo",
    "outputId": "0c5b9cd0-af8a-4564-fbad-41d844e54822"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(1.0449)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "q.var()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T1tQx7oeRvtc",
    "outputId": "3541ca1a-7447-4ef7-835e-81824aebc1b5"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(1.0700)"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "wei.var()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MLb_odHU3iKM",
    "outputId": "a687a222-5a2c-4cdb-c1bf-17cd05b45b69"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(1.0918)"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JB82yzt44REI",
    "outputId": "f07da2f1-10bb-4a7a-bcaa-578587977d00"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*8, dim=-1) # gets too peaky, converges to one-hot\n",
    "#Then there is a possibility that node is aggregated by a single other node which wont be good. like over fitting? in this case depending on a single token instead of many(Shouldnt lose context)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mpt8569BB9_f",
    "outputId": "5d8b910a-6192-44ba-ebb2-497d88e0b629",
    "ExecuteTime": {
     "end_time": "2024-09-04T00:39:44.273316Z",
     "start_time": "2024-09-04T00:39:44.268423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 151
  },
  {
   "cell_type": "code",
   "source": [
    "class LayerNorm1d: # (used to be BatchNorm1d)\n",
    "\n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    self.eps = eps\n",
    "    self.gamma = torch.ones(dim)\n",
    "    self.beta = torch.zeros(dim)\n",
    "\n",
    "  def __call__(self, x):\n",
    "    # calculate the forward pass\n",
    "    xmean = x.mean(1, keepdim=True) # batch mean\n",
    "    xvar = x.var(1, keepdim=True) # batch variance\n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "    self.out = self.gamma * xhat + self.beta\n",
    "    return self.out\n",
    "\n",
    "  def parameters(self):\n",
    "    return [self.gamma, self.beta]\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "module = LayerNorm1d(100)\n",
    "x = torch.randn(32, 100) # batch size 32 of 100-dimensional vectors\n",
    "x = module(x)\n",
    "x.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Num7sX9CKOH",
    "outputId": "929ceb78-a639-41d6-aac7-12997b5c93f0",
    "ExecuteTime": {
     "end_time": "2024-09-04T00:55:24.801611Z",
     "start_time": "2024-09-04T00:55:24.793245Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 153
  },
  {
   "cell_type": "code",
   "source": [
    "x[:,0].mean(), x[:,0].std() # mean,std of one feature across all batch inputs"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "633T2cmnW1uk",
    "outputId": "7720fa58-0478-4e8a-86a7-502d4cce9443",
    "ExecuteTime": {
     "end_time": "2024-09-04T00:55:25.976654Z",
     "start_time": "2024-09-04T00:55:25.970102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1469), tensor(0.8803))"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 154
  },
  {
   "cell_type": "code",
   "source": [
    "x[0,:].mean(), x[0,:].std() # mean,std of a single input from the batch, of its features"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LN9cK9BoXCYb",
    "outputId": "6368ece0-600e-417d-8a91-7c1e5d750ba8",
    "ExecuteTime": {
     "end_time": "2024-09-04T00:55:27.323711Z",
     "start_time": "2024-09-04T00:55:27.318402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-9.5367e-09), tensor(1.0000))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 155
  }
 ]
}
